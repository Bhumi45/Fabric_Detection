# Fabric Detection Project - Colab Notebooks

This branch contains the Google Colab notebooks used in the **Fabric Detection Project** for prototyping, model training, and evaluation. 
These notebooks document the initial stages of the project, where various machine learning models were trained and evaluated.

The reason behind using Google Colab was higher requirements of compute resources to train our model.

## Understanding the Colab Notebooks

`feature_extraction.ipynb` - Performs Feature Extraction as done locally on our system with no changes.<br>
`Model_Training_RAPIDS.ipynb` - In this notebook executed on Google Colab Pro, we utilized the NVIIDA RAPIDS to train and validate our model using nested cross validation.
But the notebook crashed again due to high CPU/GPU usage. In the next notebooks we decided to limit our memory usage.

To limit our compute usage we used the following approaches:
1. Optimize the ndarray data types of the features array(X), labels array(y) and groups array(groups) .
2. We are not using the NVIDIA RAPIDS & CuPy library and transferring all our load on our CPU. This is because we aim to reducce our computational load to an extent that we do not require the use of a GPU.
3. Reduced the train data size from 80% to 70%.
4. Reduced the outer loop folds of nested cross validation from 5 to 3 while keeping the inner loop folds the same as 3.
5. Saving intermediate models generated by each complete iteration of RandomizedSearchCV to avoid redundant iterations when retraining the same models.
6. Freeing up memory using Python's garbage collection module(gc) after one complete iteration of the outer cross vaildation loop.
7. Deleting variables not in use as & whenever required

`Feature_engineering.ipynb` implements optimization of the ndarray data types<br>
`Memory_optimzd_Model_Training.ipynb` implements the other techniques described above.

### Poor Performance of Model

**After implementing the memory optimization techniques we successfully trained the model and evaluated using nested cross validation.**<br>
The performance metrics of the Nested Cross Validation revealed the poor performance of our model. <br>
The various insights into the model performance are given in [Model Performance](https://github.com/Parthsarthi-lab/Fabric_Detection/blob/colab_notebooks_branch/MODEL_PERFORMANCE.md)

#### To analyze the **reasons** behind the poor performance of our models(both SVM & Random Forest) we went through the following approaches step by step:
1. Validated our feature extraction methods again by visually analyzing the features extracted from each class of fabric by each method over a large number of images:
    - Our feature extraction technqiues were able to identify significant features from the fabric images.

2. [Model Performance](https://github.com/Parthsarthi-lab/Fabric_Detection/blob/colab_notebooks_branch/MODEL_PERFORMANCE.md)
 suggested RandomForestClassifier performing slightly better than SVM.
   - We further applied more hyperparameter tuning with RandomForestClassifier in `model_training_1_only_RF.ipynb`
   - No improvement was seen in the RFClassifier's performance
     
3. Validated whether our choice of fabric categories was correct or not:
   - We are originally using the following fabric categories for classification: cotton, corduroy, denim, wool & linen.
   - On reiterating through our literature review, we came to know that corduroy can be made from  cotton,wool and linen.
   - This means that an image of corduroy fabric may be classified as cotton, corduroy ,wool and linen at the same time since the material used to make corduroy is cotton, wool, or linen. This may arise confusion in our model and may be responsible for the poor performance of our model.
   - Through our literature review we also came to know that denim can be made from cotton & linen, thus again confusing our model between the fabrics.
   - **Taking all these discrepancies into consideration we now decided to only go with two fabric categories, viz., corduroy and denim**
  
4. Checked the amount of explained variance of our data at different values of PCA components(`n_components`):
   - Created a new notebook `PCA_explained_variance.ipynb` to understand the explained variance at different levels of `n_components`.
   - n_components=1000 & n_components=2000 had a cumulative variance of only 44% & 60% respectively.
   - n_components=3000 & n_components=4000 had a cumulative variance of 70% & 78% respectively.
   - Decided to go with the maximum number of principal components by taking `n_components=None`.

5. **Decided to go only with RandomForestClassifier**
     - We could have still gone ahead with both Support Vector Machines  and RandomForestClassifier because the model performance of RandomForestClassifier was only slightly
       more than that of Support Vector Machines.
     - To reduce the complexity of the project we decided to go ahead with RandomForestClassifier only though SVM can be implemented in a similar way.

### Retraining our Model 
1. `NEw_feature_extraction.ipynb` extracted the features from the dataset which was now limited to only **corduroy** and **denim**.
2. `category_changed_model_training_1_only_RF.ipynb` & `category_changed_model_training_2_only_RF.ipynb` implemented Nested Cross Validation with RFClassifier.
3. This time the performance of the model significantly improved to a macro average F1 score of approx. 85% from the earlier 51%. For more details check  `category_changed_model_training_1_only_RF.ipynb` & `category_changed_model_training_2_only_RF.ipynb`
