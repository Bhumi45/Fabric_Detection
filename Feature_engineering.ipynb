{"cells":[{"cell_type":"markdown","source":["This Feature Engineering Notebook is a step-forward from the learnings of the notebook `Model_Training_RAPIDS.ipynb` to decrease the use of computational resources to train our model hassle-free.<br>\n","In this notebook, we try to optimize the data types of the arrays for the features, labels and groups to save the computational resources required during feature extraction and also model training.<br>\n"],"metadata":{"id":"OSCu8vpQdvw3"}},{"cell_type":"markdown","source":["### Results:\n","1. By converting the features array(X) from float64 to float16, we brough down the memory usage from around `7 GB to 1.5 GB`.\n","2. By converting the labels array(y) from int64 to uint8 we, we brought down the memory usage from `1.43e-04 GB to 1.7875e-05 GB`.\n","3. By converting the labels array(y) from int64 to int16 we, we brought down the memory usage from `1.43e-04 GB to 3.575e-05 GB`.\n","\n","`While converting one data type to another it was ensured that the precision of the numbers inside the arrays was not lost`"],"metadata":{"id":"bEL6ImCZgZOo"}},{"cell_type":"markdown","metadata":{"id":"vZxY44m0iblX"},"source":["### Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nBBKrrhibla"},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import cupy as cp  # CuPy for GPU-based NumPy operations\n","import numpy as np\n","import tensorflow as tf\n","import scipy\n","from skimage.feature import local_binary_pattern\n","from skimage.filters import gabor\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["#!pip install cupy --no-cache-dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0G1NJ9ANB5uW","executionInfo":{"status":"ok","timestamp":1727505182869,"user_tz":-330,"elapsed":30396,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"77eb2403-7287-4282-f6e2-2e5eb6c01131"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cupy\n","  Downloading cupy-13.3.0.tar.gz (3.4 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m167.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from cupy) (1.26.4)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.2)\n","Building wheels for collected packages: cupy\n","Y\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for cupy (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for cupy\n","Failed to build cupy\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (cupy)\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"KZSZs8B9ibld"},"source":["### Feature Extraction"]},{"cell_type":"markdown","metadata":{"id":"PAhivoGgibld"},"source":["**Define the paths for the images**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaZB5uAxjmQN","executionInfo":{"status":"ok","timestamp":1727515028646,"user_tz":-330,"elapsed":29918,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"85b574c2-9689-4c8c-cdab-aa7b1e59011a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qalnLJ4ible"},"outputs":[],"source":["# Define paths\n","dataset_dir = \"/content/drive/My Drive/Fabric Detection Project/textures 3\"\n","categories = ['cotton', 'corduroy', 'denim', 'linin', 'wool']"]},{"cell_type":"markdown","metadata":{"id":"sKetwRX2ible"},"source":["**Canny Edge Detection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RbvGwD3ible"},"outputs":[],"source":["def extract_canny_edge_detection(image):\n","    \"\"\" image must be passes to the function in grayscale\"\"\"\n","    # Step 1: Enhance contrast (optional)\n","    equalized_image = cp.asarray(cv2.equalizeHist(cp.asnumpy(image)))\n","\n","    # Step 2: Apply Gaussian Blur to reduce noise\n","    blurred_image = cp.asarray(cv2.GaussianBlur(cp.asnumpy(equalized_image), (3, 3), 1))\n","\n","    # Step 3: Apply Canny Edge Detection with adjusted thresholds (convert back and forth)\n","    edges = cp.asarray(cv2.Canny(cp.asnumpy(blurred_image), 30, 30))\n","\n","    return edges"]},{"cell_type":"markdown","metadata":{"id":"H1RIWzDqiblf"},"source":["**Gabor Filtering**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4dwvy1iiblf"},"outputs":[],"source":["def extract_gabor_filters(image):\n","    \"\"\" image must be in grayscale\"\"\"\n","\n","    def build_kernels():\n","        # Parameters\n","        gabor_kernels = []\n","        angles = [0, cp.pi/4, cp.pi/2, 3*cp.pi/4]  # Use CuPy for angles\n","        ksize = 31  # Size of the filter\n","        sigma = 4.0  # Standard deviation of the Gaussian envelope\n","        lambd = 10.0  # Wavelength of the sinusoidal factor\n","        gamma = 0.5  # Spatial aspect ratio\n","        psi = 0  # Phase offset\n","\n","        # Create Gabor kernels\n","        for theta in np.deg2rad([45, 135]):  # Convert degrees to radians\n","            kernel = cp.asarray(cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)) # Using Cupy array\n","            gabor_kernels.append(kernel)\n","\n","        return gabor_kernels\n","\n","\n","    gabor_kernels = build_kernels()\n","\n","    gabor_features = []\n","\n","    for kernel in gabor_kernels:\n","        fimg = cp.asarray(cv2.filter2D(cp.asnumpy(image), cv2.CV_8UC3, cp.asnumpy(kernel)))\n","        gabor_features.append(fimg)\n","\n","    gabor_features = cp.array(gabor_features).flatten()\n","\n","    return gabor_features"]},{"cell_type":"markdown","metadata":{"id":"0Xfgbxs7iblf"},"source":["**Local Binary Pattern**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-d_j0Dwiblf"},"outputs":[],"source":["def extract_local_binary_pattern(image):\n","\n","    # Parameters\n","    radius = 1\n","    n_points = 8 * radius\n","\n","\n","    lbp = local_binary_pattern(cp.asnumpy(image), n_points, radius, method=\"uniform\")\n","    (hist, _) = cp.histogram(cp.asarray(lbp).ravel(), bins=cp.arange(0, n_points + 3),\n","                             range=(0, n_points + 2))\n","    hist = hist.astype(\"float\")\n","    hist /= (hist.sum() + 1e-6)\n","\n","    return hist"]},{"cell_type":"markdown","metadata":{"id":"nA2JULNriblg"},"source":["**Feature Extraction**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CQjeI6Piblg"},"outputs":[],"source":["# Function to extract features from an image\n","def extract_features(image):\n","    # Convert to grayscale using CuPy arrays\n","    gray = cp.asarray(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n","\n","    # Canny edge detection\n","    edges = extract_canny_edge_detection(gray)\n","\n","    # Gabor Filter responses\n","    gabor_features=  extract_gabor_filters(gray)\n","\n","    # Local Binary Patterns (LBP)\n","    hist = extract_local_binary_pattern(gray)\n","\n","    # Combine features: edges, Gabor, and LBP\n","    features = cp.hstack([edges.flatten(), gabor_features, hist])\n","    features = cp.asnumpy(features)\n","\n","    return features # Return features back as NumPy array for further processing"]},{"cell_type":"markdown","metadata":{"id":"-Obsdnw9iblh"},"source":["### Modified code for grouping of images and also including the original image with its augmentations. Also creating only 4 augmentations of each original image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CS1U3Bf5iblh","executionInfo":{"status":"ok","timestamp":1727515407320,"user_tz":-330,"elapsed":358283,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"87a078ff-56e0-4ed8-80ea-5c136927d265"},"outputs":[{"output_type":"stream","name":"stdout","text":["OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"," Error processing image: /content/drive/My Drive/Fabric Detection Project/textures 3/corduroy/.ipynb_checkpoints, .ipynb_checkpoints\n","\n"]}],"source":["# Prepare dataset, labels, and groups\n","X = []\n","y = []\n","groups = []  # This will store the group IDs\n","\n","# Image Augmentation using TensorFlow\n","datagen = ImageDataGenerator(\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    brightness_range=[0.8, 1.2],\n","    shear_range=0.4\n",")\n","\n","group_id = 0  # Initialize group ID\n","\n","for category in categories:\n","    path = os.path.join(dataset_dir, category)\n","    label = category\n","\n","    for count, img_name in enumerate(os.listdir(path), start=1):\n","\n","        img_path = os.path.join(path, img_name)\n","        image = cv2.imread(img_path)\n","\n","        try:\n","            # Apply data augmentation and extract features\n","            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n","\n","            # Extract features from the original image\n","            original_features = extract_features(image)\n","            X.append(original_features)\n","            y.append(label)\n","            groups.append(group_id)  # Assign the group ID to the original image\n","\n","            # Prepare for augmentation\n","            image = np.expand_dims(image, axis=0)\n","            aug_iter = datagen.flow(image, batch_size=1)\n","\n","            # Perform 4 augmentations per image\n","            for _ in range(4):\n","                aug_img = next(aug_iter)[0].astype(np.uint8)\n","                features = extract_features(aug_img)\n","                X.append(features)\n","                y.append(label)\n","                groups.append(group_id)  # Assign the same group ID to the augmentations\n","\n","            # Increment group ID for the next image and its augmentations\n","            group_id += 1\n","\n","        except Exception as e:\n","            print(f\"{e} Error processing image: {img_path}, {img_name}\")\n","\n","\n","print()"]},{"cell_type":"markdown","source":["## Feature Engineering"],"metadata":{"id":"SiNB3t2jUh3D"}},{"cell_type":"markdown","source":["**Converting X, y, groups from lists to ndarrays**"],"metadata":{"id":"9iKm3yaAUlXz"}},{"cell_type":"code","source":["# Checking the data type of X,y and groups\n","print(f\"Type of X {type(X)}\")\n","print(f\"Type of y {type(y)}\")\n","print(f\"Type of groups {type(groups)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xM9pSuemSgPz","executionInfo":{"status":"ok","timestamp":1727515412447,"user_tz":-330,"elapsed":645,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"3ebe8795-0277-4ae2-c7b5-968ad4462445"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of X <class 'list'>\n","Type of y <class 'list'>\n","Type of groups <class 'list'>\n"]}]},{"cell_type":"code","source":["# Convert lists to NumPy arrays\n","X = np.array(X)\n","y = np.array(y)\n","groups = np.array(groups)"],"metadata":{"id":"8f43V0hdSnNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking the data type of X,y and groups\n","print(f\"Type of X {type(X)}\")\n","print(f\"Type of y {type(y)}\")\n","print(f\"Type of groups {type(groups)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFGRP_1sTFHC","executionInfo":{"status":"ok","timestamp":1727515416427,"user_tz":-330,"elapsed":6,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"1f906864-2ead-47be-d294-c972e39a1156"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of X <class 'numpy.ndarray'>\n","Type of y <class 'numpy.ndarray'>\n","Type of groups <class 'numpy.ndarray'>\n"]}]},{"cell_type":"markdown","source":["**Shape of X, y, groups**"],"metadata":{"id":"XAhuPuzuUtGh"}},{"cell_type":"code","source":["# Checking the shape of the dataset and the labels\n","print(f\"Dataset shape: {X.shape}\")\n","print(f\"Labels shape: {y.shape}\")\n","print(f\"Groups shape: {groups.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T87MYemSSpSb","executionInfo":{"status":"ok","timestamp":1727515421379,"user_tz":-330,"elapsed":739,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"7d44507b-c2f4-4430-9a42-2d52460c1034"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset shape: (17875, 49162)\n","Labels shape: (17875,)\n","Groups shape: (17875,)\n"]}]},{"cell_type":"markdown","source":["### Inspecting the dtypes to save memory"],"metadata":{"id":"Y70cNaiMUwx6"}},{"cell_type":"code","source":["print(f\"Dtype of X {X.dtype}\")\n","print(f\"Dtype of y {y.dtype}\")\n","print(f\"Dtype of groups {groups.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pn9PzzcIS73h","executionInfo":{"status":"ok","timestamp":1727515425689,"user_tz":-330,"elapsed":669,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"25ed96a0-58c9-4bd6-a127-b93efeb20eee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dtype of X float64\n","Dtype of y <U8\n","Dtype of groups int64\n"]}]},{"cell_type":"markdown","source":["**Inspecting the dtype of X**"],"metadata":{"id":"2zZL7IeRU2Za"}},{"cell_type":"code","source":["print(f\"Dtype of X {X.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTSe0T5vU9m4","executionInfo":{"status":"ok","timestamp":1727515429781,"user_tz":-330,"elapsed":660,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"b5def42e-d611-4c37-c443-75c463da5b66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dtype of X float64\n"]}]},{"cell_type":"code","source":["# Checking the size of X in GB\n","print(f\"Size(GB) of X {X.nbytes/1e9}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJrE5YobTJGk","executionInfo":{"status":"ok","timestamp":1727515432893,"user_tz":-330,"elapsed":5,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"0a8684a8-c74c-4fe7-a306-33f5ae9bd2e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size(GB) of X 7.030166\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Check if any values have non-zero decimals\n","has_decimals = np.any(X != np.floor(X))\n","\n","if not has_decimals:\n","    # Convert the array to int32 if no decimals\n","    X = X.astype(np.int32)\n","    print(\"Array converted to int32 without decimals.\")\n","else:\n","    print(\"Array contains non-zero decimals.\")\n","\n","print(f\"Size(GB) of X {X.nbytes/1e9}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwyWMAIPTLFC","executionInfo":{"status":"ok","timestamp":1727515440746,"user_tz":-330,"elapsed":3763,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"3052f4f6-76f3-4971-9e36-4ed3a5b18ad7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Array contains non-zero decimals.\n","Size(GB) of X 7.030166\n"]}]},{"cell_type":"code","source":["len(np.unique(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PdUIf4CTOLQ","executionInfo":{"status":"ok","timestamp":1727515473983,"user_tz":-330,"elapsed":25379,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"3721bb6c-df4f-420e-c020-d85bee6c3d0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5840"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Check if values exceed float16 limits\n","float16_min = np.finfo(np.float16).min\n","float16_max = np.finfo(np.float16).max\n","\n","# Check if any value is outside the float32 range\n","if np.any(X < float16_min) or np.any(X > float16_max):\n","    print(\"Array contains values outside the float16 range.\")\n","else:\n","    print(\"All values are within the float16 range.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46WbEqbnTO8C","executionInfo":{"status":"ok","timestamp":1727515487985,"user_tz":-330,"elapsed":3226,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"7b7e9153-2017-4a19-8371-9b4c71db69a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All values are within the float16 range.\n"]}]},{"cell_type":"code","source":["# Converting X from float64 to float16\n","# Checking the size of X in GB\n","print(f\"Size(GB) of X when float64 {X.nbytes/1e9}\")\n","\n","X = X.astype(np.float16)\n","\n","# Checking the size of X in GB\n","print(f\"Size(GB) of X after converting to float16 {X.nbytes/1e9}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWtTzGjITTt6","executionInfo":{"status":"ok","timestamp":1727515498953,"user_tz":-330,"elapsed":6083,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"90ce0b0b-3435-41a7-cb5a-8e097cf9e942"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size(GB) of X when float64 7.030166\n","Size(GB) of X after converting to float16 1.7575415\n"]}]},{"cell_type":"markdown","source":["**Inspecting the dtype of y**"],"metadata":{"id":"GGk-MOwcWcoc"}},{"cell_type":"markdown","source":["1. Encoding y"],"metadata":{"id":"xE9HFiELWkUJ"}},{"cell_type":"code","source":["# Example array with categories\n","categories = ['linen', 'cotton', 'wool', 'denim', 'corduroy']\n","\n","# Create a dictionary for manual mapping\n","category_mapping = { 'corduroy': 1, 'cotton': 2, 'denim': 3, 'linin': 4, 'wool': 5}\n","\n","# Convert to pandas Series (optional if already in pandas)\n","y_series = pd.Series(y)\n","\n","# Map categories to numbers\n","mapped_categories = y_series.map(category_mapping)\n","y = np.array(mapped_categories)\n","\n","\n","print(y)\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GR9S7NZhSq8a","executionInfo":{"status":"ok","timestamp":1727515519315,"user_tz":-330,"elapsed":936,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"4c17d131-6324-4507-f052-b0bda32959eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2 2 2 ... 5 5 5]\n","(17875,)\n"]}]},{"cell_type":"code","source":["# Freeing up memory\n","del y_series\n","del mapped_categories"],"metadata":{"id":"5MsgDz3vWuJZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Checking the dtye of y"],"metadata":{"id":"L10U1FXjWo5C"}},{"cell_type":"code","source":["print(f\"Dtype of y {y.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgMA7YsAS1nG","executionInfo":{"status":"ok","timestamp":1727515530035,"user_tz":-330,"elapsed":689,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"b0a83c52-b3a4-4373-a0ba-e04e96ad0bf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dtype of y int64\n"]}]},{"cell_type":"code","source":["print(f\"Size(GB) of y {y.nbytes/1e9}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7DzX1pXW5Vw","executionInfo":{"status":"ok","timestamp":1727515532621,"user_tz":-330,"elapsed":6,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"9eab9ec3-48a9-422f-db02-9acc45543b91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size(GB) of y 0.000143\n"]}]},{"cell_type":"code","source":["print(np.unique(y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9e1L5o0WX8g","executionInfo":{"status":"ok","timestamp":1727515535168,"user_tz":-330,"elapsed":6,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"346475dc-b89c-4099-ed5f-5b4e3da5ea18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 2 3 4 5]\n"]}]},{"cell_type":"code","source":["# Converting the dtype of y to uint8\n","y = y.astype(np.uint8)\n","\n","print(f\"Dtype of y {y.dtype}\")\n","print(f\"Size(GB) of y {y.nbytes/1e9}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFAt6hgjWX5r","executionInfo":{"status":"ok","timestamp":1727515537879,"user_tz":-330,"elapsed":5,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"11732a72-7b4c-4fa4-827b-b9a376b263f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dtype of y uint8\n","Size(GB) of y 1.7875e-05\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XR_J-yAEWX22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Inspecting the dtype of groups**"],"metadata":{"id":"_rP6hqwoXwon"}},{"cell_type":"code","source":["print(f\"Dtype of groups {groups.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqgyWnIVXz0I","executionInfo":{"status":"ok","timestamp":1727515552501,"user_tz":-330,"elapsed":720,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"ceee644b-7380-4f2b-bb79-fee21e16169c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dtype of groups int64\n"]}]},{"cell_type":"code","source":["# Get the min and max values for int8\n","int8_min = np.iinfo(np.int8).min\n","int8_max = np.iinfo(np.int8).max\n","\n","# Check if all values fall within the int8 range\n","if np.all((groups >= int8_min) & (groups <= int8_max)):\n","    print(\"All values fall within the int8 range.\")\n","else:\n","    print(\"Some values are outside the int8 range.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEFciUXk8735","executionInfo":{"status":"ok","timestamp":1727515617428,"user_tz":-330,"elapsed":1969,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"62198f5d-a1da-4aac-9beb-b0b7d2a65860"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Some values are outside the int8 range.\n"]}]},{"cell_type":"code","source":["# Get the min and max values for int16\n","int16_min = np.iinfo(np.int16).min\n","int16_max = np.iinfo(np.int16).max\n","\n","# Check if all values fall within the int16 range\n","if np.all((groups >= int16_min) & (groups <= int16_max)):\n","    print(\"All values fall within the int16 range.\")\n","else:\n","    print(\"Some values are outside the int16 range.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5mD650VYlg6","executionInfo":{"status":"ok","timestamp":1727515624656,"user_tz":-330,"elapsed":2940,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"cbcce35e-de6e-4b44-fc71-28175de94731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All values fall within the int16 range.\n"]}]},{"cell_type":"code","source":["# Changing the dtype of groups into int32\n","print(f\"Size of groups when int64 is {groups.nbytes/1e9}\")\n","groups = groups.astype(np.int16)\n","print(f\"Size of groups after changing to int16 is {groups.nbytes/1e9}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OidaFcg6WX0P","executionInfo":{"status":"ok","timestamp":1727515630142,"user_tz":-330,"elapsed":664,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"97f9e74b-f30f-4d90-8060-74fdd534fe16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of groups when int64 is 0.000143\n","Size of groups after changing to int16 is 3.575e-05\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ge5tiv-fXrdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jdJfUBXVXra5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3mzsYdr5XrX7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-ph9BIimXrSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D6RpWJj-XrPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xb772p5Bibli","executionInfo":{"status":"ok","timestamp":1727515652929,"user_tz":-330,"elapsed":5249,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"9657cff8-296d-41e2-86b0-23c7fd34d37d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data, labels, and groups have been saved to /content/drive/My Drive/Fabric Detection Project/Extracted Features\n"]}],"source":["\n","# Path to the 'Extracted Features' directory\n","save_dir = \"/content/drive/My Drive/Fabric Detection Project/Extracted Features\"\n","\n","# Create 'Extracted Features' directory if it doesn't exist\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","# Save each array as a separate .npz file\n","np.savez(os.path.join(save_dir, 'X.npz'), data=X)\n","np.savez(os.path.join(save_dir, 'y.npz'), labels=y)\n","np.savez(os.path.join(save_dir, 'groups.npz'), groups=groups)\n","\n","print(f\"Data, labels, and groups have been saved to {save_dir}\")\n"]},{"cell_type":"code","source":["# Estimate the size of each array in gigabytes (in memory)\n","import sys\n","data_size = sys.getsizeof(X) / (1024 * 1024 * 1024)\n","labels_size = sys.getsizeof(y) / (1024 * 1024 * 1024)\n","groups_size = sys.getsizeof(groups) / (1024 * 1024 * 1024)\n","\n","print(f\"Size of the data.npz :{data_size}\")\n","print(f\"Size of the labels.npz :{labels_size}\")\n","print(f\"Size of the groups.npz :{groups_size}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtzqMnEcsfoI","executionInfo":{"status":"ok","timestamp":1727515642329,"user_tz":-330,"elapsed":1207,"user":{"displayName":"Parthsarthi Joshi","userId":"13110895326430403805"}},"outputId":"abdd5bee-07fa-4f3b-b295-12a75ba304e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the data.npz :1.6368381939828396\n","Size of the labels.npz :1.6751699149608612e-05\n","Size of the groups.npz :3.339909017086029e-05\n"]}]},{"cell_type":"markdown","metadata":{"id":"qOXi5nBVibll"},"source":["**Loading the saved data and labels**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yRocp5Piblm"},"outputs":[],"source":["# Load from the .npz file\n","loaded_data = np.load('Extracted_features\\\\data.npz')\n","loaded_labels = np.load('Extracted_features\\\\labels.npz')\n","loaded_groups = np.load('Extracted_features\\\\groups.npz')\n","\n","data_loaded = loaded_data[\"data\"]\n","labels_loaded = loaded_labels[\"labels\"]\n","groups_loaded = loaded_labels[\"groups\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpbZEV4tiblm","outputId":"44a0ab8b-8d0e-4847-d653-c5e87a977363"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shape: (17780, 49162)\n","Labels shape: (17780,)\n"]}],"source":["# Checking the shape of the dataset and the labels\n","print(f\"Dataset shape: {data_loaded.shape}\")\n","print(f\"Labels shape: {labels_loaded.shape}\")\n","print(f\"Groups shape: {groups_loaded.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"B137FgZLiblq"},"source":["From the above output we can see that we have **49162 features** and **17780 rows**"]},{"cell_type":"code","source":[],"metadata":{"id":"3lJwWYzjRLEg"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}