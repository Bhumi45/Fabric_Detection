{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import cupy as cp  # CuPy for GPU-based NumPy operations\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.filters import gabor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "print(os.getenv('TF_ENABLE_ONEDNN_OPTS'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the paths for the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_dir = \"textures 3\"\n",
    "categories = ['cotton', 'corduroy', 'denim', 'linin', 'wool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canny Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_canny_edge_detection(image):\n",
    "    \"\"\" image must be passes to the function in grayscale\"\"\"\n",
    "    # Step 1: Enhance contrast (optional)\n",
    "    equalized_image = cp.asarray(cv2.equalizeHist(cp.asnumpy(image)))\n",
    "    \n",
    "    # Step 2: Apply Gaussian Blur to reduce noise\n",
    "    blurred_image = cp.asarray(cv2.GaussianBlur(cp.asnumpy(equalized_image), (3, 3), 1))\n",
    "    \n",
    "    # Step 3: Apply Canny Edge Detection with adjusted thresholds (convert back and forth)\n",
    "    edges = cp.asarray(cv2.Canny(cp.asnumpy(blurred_image), 30, 30))\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gabor Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gabor_filters(image):\n",
    "    \"\"\" image must be in grayscale\"\"\"\n",
    "    \n",
    "    def build_kernels():\n",
    "        # Parameters\n",
    "        gabor_kernels = []\n",
    "        angles = [0, cp.pi/4, cp.pi/2, 3*cp.pi/4]  # Use CuPy for angles\n",
    "        ksize = 31  # Size of the filter\n",
    "        sigma = 4.0  # Standard deviation of the Gaussian envelope\n",
    "        lambd = 10.0  # Wavelength of the sinusoidal factor\n",
    "        gamma = 0.5  # Spatial aspect ratio\n",
    "        psi = 0  # Phase offset\n",
    "\n",
    "        # Create Gabor kernels\n",
    "        for theta in np.deg2rad([45, 135]):  # Convert degrees to radians\n",
    "            kernel = cp.asarray(cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)) # Using Cupy array\n",
    "            gabor_kernels.append(kernel)\n",
    "\n",
    "        return gabor_kernels\n",
    "\n",
    "\n",
    "    gabor_kernels = build_kernels()\n",
    "    \n",
    "    gabor_features = []\n",
    "\n",
    "    for kernel in gabor_kernels:\n",
    "        fimg = cp.asarray(cv2.filter2D(cp.asnumpy(image), cv2.CV_8UC3, cp.asnumpy(kernel)))\n",
    "        gabor_features.append(fimg)\n",
    "\n",
    "    gabor_features = cp.array(gabor_features).flatten()\n",
    "\n",
    "    return gabor_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Binary Pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_local_binary_pattern(image):\n",
    "\n",
    "    # Parameters \n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "\n",
    "    \n",
    "    lbp = local_binary_pattern(cp.asnumpy(image), n_points, radius, method=\"uniform\")\n",
    "    (hist, _) = cp.histogram(cp.asarray(lbp).ravel(), bins=cp.arange(0, n_points + 3),\n",
    "                             range=(0, n_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an image\n",
    "def extract_features(image):\n",
    "    # Convert to grayscale using CuPy arrays\n",
    "    gray = cp.asarray(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # Canny edge detection\n",
    "    edges = extract_canny_edge_detection(gray)\n",
    "    \n",
    "    # Gabor Filter responses\n",
    "    gabor_features=  extract_gabor_filters(gray)\n",
    "    \n",
    "    # Local Binary Patterns (LBP)\n",
    "    hist = extract_local_binary_pattern(gray)\n",
    "    \n",
    "    # Combine features: edges, Gabor, and LBP\n",
    "    features = cp.hstack([edges.flatten(), gabor_features, hist])\n",
    "    features = cp.asnumpy(features)\n",
    "    \n",
    "    return features # Return features back as NumPy array for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Extraction Method 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Data Structures**\n",
    "  - `data`: Stores extracted features from augmented images.\n",
    "  - `labels`: Stores corresponding labels for each image.\n",
    "\n",
    "2. **Feature Extraction and Augmentation**\n",
    "\n",
    "- For each image:\n",
    "  - Resizes to 128x128 pixels and prepares for augmentation.\n",
    "  - Initializes an augmentation iterator.\n",
    "  - Generates 4 augmented versions\n",
    "  - **Features are extracted only from the augmented images** and appending them to `data` and `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Image Augmentation using TensorFlow\n",
    "datagen = ImageDataGenerator(\n",
    "    #rotation_range=15,        # Random rotations up to 15 degrees\n",
    "    #width_shift_range=0.1,    # Horizontal shifts\n",
    "    #height_shift_range=0.1,   # Vertical shifts\n",
    "    horizontal_flip=True,     # Flip images horizontally\n",
    "    vertical_flip=True,       # Flip images vertically\n",
    "    #zoom_range=0.2,           # Random zoom\n",
    "    brightness_range=[0.8, 1.2], # Brightness adjustment\n",
    "    shear_range=0.4           # Shear transformation\n",
    ")\n",
    "\n",
    "for num,category in enumerate(categories):\n",
    "    path = os.path.join(dataset_dir, category)\n",
    "    label = category\n",
    "    \n",
    "    for count,img_name in enumerate(os.listdir(path),start=1):\n",
    "\n",
    "        if count==2:\n",
    "            print(f\"Shape of the features: {features.shape}\")\n",
    "\n",
    "\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        try:\n",
    "            # Apply data augmentation and extract features\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n",
    "            image = np.expand_dims(image, axis=0)  # Prepare for augmentation\n",
    "            aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "            # Perform 4 augmentations per image\n",
    "            for _ in range(4):\n",
    "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                features = extract_features(aug_img)\n",
    "                data.append(features)\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_path,img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Extraction Method 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Structures**\n",
    "- **`data`**: Stores extracted features for both original and augmented images.\n",
    "- **`labels`**: Stores labels corresponding to each image.\n",
    "- **`groups`**: Tracks group IDs, assigning each original image and its augmentations the same group ID.\n",
    "\n",
    "\n",
    "2. **Group ID Management**\n",
    "- A unique `group_id` is assigned to each original image and its corresponding augmentations.\n",
    "- The `group_id` is incremented for each new image processed.\n",
    "- This is required in the step of nested cross validation to allow the same group of images to be either in the training folds or the testing fold , not both.\n",
    "\n",
    "3. **Feature Extraction**\n",
    "- **Features are extracted for the original images as well as their augmented versions.**\n",
    "- For each original image, we have 4 augmentations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: textures 3/corduroy/.ipynb_checkpoints, .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset, labels, and groups\n",
    "data = []\n",
    "labels = []\n",
    "groups = []  # This will store the group IDs\n",
    "\n",
    "# Image Augmentation using TensorFlow\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,     \n",
    "    vertical_flip=True,       \n",
    "    brightness_range=[0.8, 1.2], \n",
    "    shear_range=0.4           \n",
    ")\n",
    "\n",
    "group_id = 0  # Initialize group ID\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(dataset_dir, category)\n",
    "    label = category\n",
    "    \n",
    "    for count, img_name in enumerate(os.listdir(path), start=1):\n",
    "        \n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        try:\n",
    "            # Apply data augmentation and extract features\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n",
    "            \n",
    "            # Extract features from the original image\n",
    "            original_features = extract_features(image)\n",
    "            data.append(original_features)\n",
    "            labels.append(label)\n",
    "            groups.append(group_id)  # Assign the group ID to the original image\n",
    "\n",
    "            # Prepare for augmentation\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "            # Perform 4 augmentations per image\n",
    "            for _ in range(4):\n",
    "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                features = extract_features(aug_img)\n",
    "                data.append(features)\n",
    "                labels.append(label)\n",
    "                groups.append(group_id)  # Assign the same group ID to the augmentations\n",
    "\n",
    "            # Increment group ID for the next image and its augmentations\n",
    "            group_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {img_path}, {img_name}\")\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the data, labels and groups as memory mapped arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "final_data = np.array(data)\n",
    "final_labels = np.array(labels)\n",
    "final_groups = np.array(groups)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"Extracted_features\"):\n",
    "    os.makedirs(\"Extracted_features\")\n",
    "\n",
    "\n",
    "data_mmap = np.memmap('Extracted_features\\\\final_data_mmap.dat', dtype='float32', mode='w+', shape=final_data.shape)\n",
    "labels_mmap = np.memmap('Extracted_features\\\\final_labels_mmap.dat', dtype='int', mode='w+', shape=final_labels.shape)\n",
    "groups_mmap = np.memmap('Extracted_features\\\\final_groups_mmap.dat', dtype='int', mode='w+', shape=final_groups.shape)\n",
    "\n",
    "# Copy data to memory-mapped files (you can do this in batches)\n",
    "data_mmap[:] = final_data[:]\n",
    "labels_mmap[:] = final_labels[:]\n",
    "groups_mmap[:] = final_groups[:]\n",
    "\n",
    "# Flush to disk\n",
    "data_mmap.flush()\n",
    "labels_mmap.flush()\n",
    "groups_mmap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Extraction Method 3**\n",
    "\n",
    "\n",
    "Storing the extracted features in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script processes images in batches for efficient memory usage, performing image augmentation, feature extraction, and saving the data incrementally using NumPy arrays.\n",
    "\n",
    "\n",
    "1. **Batch Saving**\n",
    "- Data is saved in batches once `batch_size` (1000 images) is reached:\n",
    "  1. Saves the current batch of data to a compressed `.npz` file using `np.savez_compressed()`.\n",
    "  2. **Memory Management**: Clears the `data`, `labels`, and `groups` lists, and forces garbage collection (`gc.collect()`) to free memory before processing the next batch.\n",
    "\n",
    "2. **Final Data Save**\n",
    "- After processing all images, if any remaining data exists that hasn't been saved, the script writes the final batch to disk.\n",
    "\n",
    "3. **Summary**\n",
    "This script efficiently processes images by augmenting them, extracting features, and saving the data in batches to avoid memory overload. It also ensures proper memory management using garbage collection after each batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: textures 3/corduroy/.ipynb_checkpoints, .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize batch size for saving\n",
    "batch_size = 1000  # You can adjust this based on memory capacity\n",
    "save_count = 0  # To track saved files\n",
    "\n",
    "# Initialize arrays\n",
    "data = []\n",
    "labels = []\n",
    "groups = []  # This will store the group IDs\n",
    "\n",
    "group_id = 0  # Initialize group ID\n",
    "\n",
    "# Image Augmentation using TensorFlow\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,     \n",
    "    vertical_flip=True,       \n",
    "    brightness_range=[0.8, 1.2], \n",
    "    shear_range=0.4           \n",
    ")\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(dataset_dir, category)\n",
    "    label = category\n",
    "\n",
    "    for count, img_name in enumerate(os.listdir(path), start=1):\n",
    "        \n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        try:\n",
    "            # Apply data augmentation and extract features\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n",
    "            \n",
    "            # Extract features from the original image\n",
    "            original_features = extract_features(image)\n",
    "            data.append(original_features)\n",
    "            labels.append(label)\n",
    "            groups.append(group_id)  # Assign the group ID to the original image\n",
    "\n",
    "            # Prepare for augmentation\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "            # Perform 4 augmentations per image\n",
    "            for _ in range(4):\n",
    "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                features = extract_features(aug_img)\n",
    "                data.append(features)\n",
    "                labels.append(label)\n",
    "                groups.append(group_id)  # Assign the same group ID to the augmentations\n",
    "\n",
    "            # Increment group ID for the next image and its augmentations\n",
    "            group_id += 1\n",
    "\n",
    "            # Save data in batches\n",
    "            if len(data) >= batch_size:\n",
    "                # Save current batch to an .npz file\n",
    "                np.savez_compressed(f'Extracted_features\\\\dataset_batch_{save_count}.npz', data=np.array(data), labels=np.array(labels), groups=np.array(groups))\n",
    "                save_count += 1\n",
    "\n",
    "                # Clear memory by resetting the arrays and forcing garbage collection\n",
    "                data.clear()\n",
    "                labels.clear()\n",
    "                groups.clear()\n",
    "                gc.collect()  # Force garbage collection to free memory\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {img_path}, {img_name}\")\n",
    "\n",
    "# Save any remaining data if exists after loop ends\n",
    "if data:\n",
    "    np.savez_compressed(f'Extracted_features\\\\dataset_batch_{save_count}.npz', data=np.array(data), labels=np.array(labels), groups=np.array(groups))\n",
    "    data.clear()\n",
    "    labels.clear()\n",
    "    groups.clear()\n",
    "    gc.collect()  # Clean up the remaining memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the data, labels and groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory where your .npz files are stored\n",
    "npz_directory = './'  # Replace with the correct directory path if necessary\n",
    "\n",
    "# Automatically list all .npz files in the directory\n",
    "npz_files = [f for f in os.listdir(npz_directory) if f.endswith('.npz')]\n",
    "\n",
    "# Initialize empty lists to store the extracted data\n",
    "all_data = []\n",
    "all_labels = []\n",
    "all_groups = []\n",
    "\n",
    "# Iterate through each saved .npz file and load the arrays\n",
    "for file in npz_files:\n",
    "    file_path = os.path.join(npz_directory, file)\n",
    "    # Load the saved .npz file\n",
    "    with np.load(file_path) as data:\n",
    "        all_data.append(data['data'])    # Append 'data' array\n",
    "        all_labels.append(data['labels']) # Append 'labels' array\n",
    "        all_groups.append(data['groups']) # Append 'groups' array\n",
    "\n",
    "# Now concatenate all arrays to create final datasets\n",
    "final_data = np.concatenate(all_data, axis=0)\n",
    "final_labels = np.concatenate(all_labels, axis=0)\n",
    "final_groups = np.concatenate(all_groups, axis=0)\n",
    "\n",
    "# Your final arrays are now ready to use\n",
    "print(\"Final data shape:\", final_data.shape)\n",
    "print(\"Final labels shape:\", final_labels.shape)\n",
    "print(\"Final groups shape:\", final_groups.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------End----------------------------------\n",
    "\n",
    "MOVE TO model_training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the saved data and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the .npz file\n",
    "loaded_data = np.load('Extracted_features\\\\data.npz')\n",
    "loaded_labels = np.load('Extracted_features\\\\labels.npz')\n",
    "loaded_groups = np.load('Extracted_features\\\\groups.npz')\n",
    "\n",
    "data_loaded = loaded_data[\"data\"]\n",
    "labels_loaded = loaded_labels[\"labels\"]\n",
    "groups_loaded = loaded_labels[\"groups\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Extraction Method 4**\n",
    "\n",
    "(using data,labels and groups directly as ndarrays rather than lists to reduce RAM usage for conversion to arrays from lists)\n",
    "\n",
    "The ndarrays are memory mapped reducing memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Feature: Memory-Mapped Arrays**\n",
    "\n",
    "- Creates a folder for storing the features, labels, and group IDs if it doesn't exist.\n",
    "- Preallocates memory-mapped arrays for efficient handling of large datasets:\n",
    "  - **`data_file`**: Stores image features.\n",
    "  - **`labels_file`**: Stores image labels.\n",
    "  - **`groups_file`**: Stores group IDs to keep track of the relationship between original and augmented images.\n",
    "- The total number of images (`total_images = 17,780`) and the feature size (`49162`) are predefined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first snippet counts the number of orginal images, number of augmented images and the total no of features extracted from each image.<br>\n",
    "Only when we know the feature size can we create a memory mapped array in advance with a defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m augmentation_per_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# As you're doing 4 augmentations per image\u001b[39;00m\n\u001b[0;32m      8\u001b[0m feature_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# To store the size of features (columns)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcategories\u001b[49m:\n\u001b[0;32m     11\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_dir, category)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m count, img_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(path), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Counting the number of rows(images) and features\n",
    "import os\n",
    "\n",
    "# Initialize counters\n",
    "total_original_images = 0\n",
    "total_augmented_images = 0\n",
    "augmentation_per_image = 4  # As you're doing 4 augmentations per image\n",
    "feature_size = None  # To store the size of features (columns)\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(dataset_dir, category)\n",
    "    \n",
    "    for count, img_name in enumerate(os.listdir(path), start=1):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        try:\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n",
    "            original_features = extract_features(image)\n",
    "            \n",
    "            # Determine feature size (columns) from the first image processed\n",
    "            if feature_size is None:\n",
    "                feature_size = original_features.shape[0]  # Assuming 1D feature vector\n",
    "            \n",
    "            # Increment counts for original and augmented images\n",
    "            total_original_images += 1\n",
    "            total_augmented_images += augmentation_per_image\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {img_path}, {img_name}\")\n",
    "\n",
    "# Total number of images = original + augmented\n",
    "total_images = total_original_images + total_augmented_images\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total original images: {total_original_images}\")\n",
    "print(f\"Total augmented images: {total_augmented_images}\")\n",
    "print(f\"Total images including augmentations: {total_images}\")\n",
    "print(f\"Number of features per image: {feature_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sceond snippet performs the real task of feature extraction storing the data, labels and groups as memory mapped arrays.<br>\n",
    "Shape of data - (total_images,feature_size)<br>\n",
    "Shape of labels - (total_images,)<br>\n",
    "Shape of groups - (total_images,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Image Augmentation using TensorFlow\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,     \n",
    "    vertical_flip=True,       \n",
    "    brightness_range=[0.8, 1.2], \n",
    "    shear_range=0.4           \n",
    ")\n",
    "\n",
    "# Step 1: Create \"Extracted_features\" folder if it doesn't exist\n",
    "output_dir = 'Extracted_features'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "# Step 2: Define file paths for the memory-mapped arrays inside the new folder\n",
    "data_file = os.path.join(output_dir, 'data_file.dat')\n",
    "labels_file = os.path.join(output_dir, 'labels_file.dat')\n",
    "groups_file = os.path.join(output_dir, 'groups_file.dat')\n",
    "# Known values\n",
    "total_images = 17780  # Total original images + augmentations\n",
    "feature_size = 49162   # Number of features per image\n",
    "\n",
    "# Step 1: Preallocate memory-mapped arrays\n",
    "data = np.memmap(data_file, dtype='float32', mode='w+', shape=(total_images, feature_size))\n",
    "labels = np.memmap(labels_file, dtype='object', mode='w+', shape=(total_images,))\n",
    "groups = np.memmap(groups_file, dtype='int32', mode='w+', shape=(total_images,))\n",
    "\n",
    "# Step 2: Feature Extraction with memory mapping\n",
    "group_id = 0  # Initialize group ID\n",
    "image_counter = 0  # Keep track of which row we are filling in the arrays\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(dataset_dir, category)\n",
    "    label = category\n",
    "    \n",
    "    for count, img_name in enumerate(os.listdir(path), start=1):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        try:\n",
    "            image = cv2.resize(image, (128, 128))  # Resize to a fixed size\n",
    "            \n",
    "            # Extract features from the original image\n",
    "            original_features = extract_features(image)\n",
    "            \n",
    "            # Store the original image's features, label, and group ID in the memory-mapped arrays\n",
    "            data[image_counter, :] = original_features  # Fill in the row corresponding to the current image\n",
    "            labels[image_counter] = label\n",
    "            groups[image_counter] = group_id\n",
    "            image_counter += 1  # Increment counter to fill the next row\n",
    "\n",
    "            # Prepare for augmentation\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "            # Perform 4 augmentations per image\n",
    "            for _ in range(4):\n",
    "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                features = extract_features(aug_img)\n",
    "                \n",
    "                # Store augmented image features, label, and group ID\n",
    "                data[image_counter, :] = features\n",
    "                labels[image_counter] = label\n",
    "                groups[image_counter] = group_id\n",
    "                image_counter += 1  # Increment counter for the next augmented image\n",
    "\n",
    "            # Increment group ID for the next set of images\n",
    "            group_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "# Flush the changes to disk to ensure everything is saved\n",
    "data.flush()\n",
    "labels.flush()\n",
    "groups.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Freeing up the memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "del data\n",
    "del labels\n",
    "del groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data,labels and groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Memory-mapped file paths\n",
    "output_dir = 'Extracted_features'\n",
    "data_file = os.path.join(output_dir, 'data_file.dat')\n",
    "labels_file = os.path.join(output_dir, 'labels_file.dat')\n",
    "groups_file = os.path.join(output_dir, 'groups_file.dat')\n",
    "\n",
    "# Known values\n",
    "total_images = 17780  # Total original images + augmentations\n",
    "feature_size = 49162   # Number of features per image \n",
    "\n",
    "# Load the memory-mapped arrays for reading\n",
    "data = np.memmap(data_file, dtype='float32', mode='r', shape=(total_images, feature_size))\n",
    "labels = np.memmap(labels_file, dtype='object', mode='r', shape=(total_images,))\n",
    "groups = np.memmap(groups_file, dtype='int32', mode='r', shape=(total_images,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17780, 49162)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data** contains the input data (X) <br>\n",
    "**Labels** contains the output data (Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (17780, 49162)\n",
      "Labels shape: (17780,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the dataset and the labels\n",
    "print(f\"Dataset shape: {data_loaded.shape}\")\n",
    "print(f\"Labels shape: {labels_loaded.shape}\")\n",
    "print(f\"Groups shape: {groups_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
